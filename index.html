<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yucao16.github.io" target="_blank">Yu Cao</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.eecs.qmul.ac.uk/~zz012/" target="_blank">Zengqun Zhao</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.eecs.qmul.ac.uk/~ioannisp/" target="_blank">Ioannis Patras</a>,
                  </span>
                  <span class="author-block">
                    <a href="http://www.eecs.qmul.ac.uk/~sgg/" target="_blank">Shaogang Gong</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Queen Mary University of London<br>CVPR 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.16218.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YuCao16/ASCED" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual artifacts remain a persistent challenge in diffusion models, even with training on massive datasets. Current solutions primarily rely on supervised detectors, yet lack understanding of why these artifacts occur in the first place. In our analysis, we identify three distinct phases in the diffusion generative process: Profiling, Mutation, and Refinement. Artifacts typically emerge during the Mutation phase, where certain regions exhibit anomalous score dynamics over time, causing abrupt disruptions in the normal evolution pattern. This temporal nature explains why existing methods focusing only on spatial uncertainty of the final output fail at effective artifact localization. Based on these insights, we propose ASCED (Abnormal Score Correction for Enhancing Diffusion), that detects artifacts by monitoring abnormal score dynamics during the diffusion process, with a trajectory-aware on-the-fly mitigation strategy that appropriate generation of noise in the detected areas. Unlike most existing methods that apply post hoc corrections, e.g., by applying a noising-denoising scheme after generation, our mitigation strategy operates seamlessly within the existing diffusion process. Extensive experiments demonstrate that our proposed approach effectively reduces artifacts across diverse domains, matching or surpassing existing supervised methods without additional training.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Motivation -->
  <section class="section" id="Motivation">
  <div class="container is-max-desktop content">
    <center>
      <h2 class="title">Motivation</h2>
    </center>
    <div class="has-text-centered">
      <div class="figure-caption mt-2" style="width: 100%; margin: 0 auto; text-align: left;">
        <strong>Why do diffusion models generate artifacts?</strong> We discover that a diffusion generative process necessarily undergoes three phases, we call them: (2) "Profiling" which recovers holistic mean templates, (2) "Mutation" which introduces local divergence, and (3) "Refinement" which rationalizes pixel-wise generation in spatial context. Four visual examples are shown: The first two rows are two examples of rational local mutations (in green boxes) either naturally integrated (Row 1) or reasonably eliminated (Row 2). The bottom two rows show two failure cases when mutations were trapped unreasonably (in red boxes), resisting refinement and resulting in artifacts. Phases are visualized in equal intervals for clarity; please zoom in for more details.
      </div>
      <img class="rounded" src="static/images/ASCED_motivation.png" alt="Motivation" width="100%" height="auto">
    </div>
  </div>
</section>
<!-- End Motivation -->

<!-- Methodology -->
  <section class="section" id="Methodology">
  <div class="container is-max-desktop content">
    <center>
      <h2 class="title">Methodology</h2>
    </center>
    <div class="has-text-centered">
      <div class="figure-caption mt-2" style="width: 100%; margin: 0 auto">
        <p>
          <strong>Diagram of our framework.</strong> Denoising and Noising are using Eq. (5) and Eq. (1) in the main paper, respectively
        </p>
      </div>
      <img class="rounded" src="static/images/ASCED_method1.png" alt="Methodology" width="100%" height="auto">
    </div>
    <div class="has-text-centered">
      <div class="figure-caption mt-2" style="width: 97%; margin: 0 auto; text-align: left;">
        <p>
          <strong>Visualization of score dynamics and visual artifact detection.</strong> (a) Generated images with detected visual artifact regions highlighted (red). (b) Visualization of score dynamics (normalized) between adjacent time steps as activation maps. Brighter regions (green to yellow) indicate areas of higher score variation, while darker regions (blue to black) show areas of lower score change. (c) Score acceleration curves comparing artifact regions (red) with non-artifact regions (blue). The artifact regions exhibit characteristic rapid acceleration followed by deceleration, while non-artifact regions maintain stable score dynamics over time throughout a generative (inference) process.
        </p>
      </div>
      <img class="rounded" src="static/images/ASCED_method2.png" alt="Methodology" width="100%" height="auto">
    </div>
  </div>
</section>
<!-- End Methodology -->

<!-- Experiment Results -->
  <section class="section" id="Results">
  <div class="container is-max-desktop content">
    <center>
      <h2 class="title">Experiment Results</h2>
    </center>
    <div class="has-text-centered">
      <div class="figure-caption mt-2" style="width: 100%; margin: 0 auto; text-align: left;">
        <p>
          <strong>Quantitative Comparisons on five datasets.</strong> The methods compared include BayesDiff [20] and SARGD [49], and three baseline methods: State Replacement Score Clipping and PAL [43] + TTC. All methods use DDIM sampling with identical noise seeds to generate 10,000 images per dataset, ensuring each approach modifies the same deterministic trajectories for fair comparison. The best scores are in bold and second best in underline with bold. Sup and UnS denote supervised and unsupervised methods, respectively.
        </p>
      </div>
      <img class="rounded" src="static/images/ASCED_results1.png" alt="Results" width="100%" height="auto">
    </div>
    <div class="has-text-centered">
      <div class="figure-caption mt-2" style="width: 100%; margin: 0 auto; text-align: left;">
        <p>
          <strong>Qualitative Comparison of different correction methods.</strong> For each example, we show the original output with visual artifacts (left) and zoomed-in views of the artifact regions corrected by different methods (right): SARGD [49], state replacement (Replace), and our trajectory-aware targeted correction (Ours). Rows from top to bottom: FFHQ[17], ImageNet[10], and LSUN-(Cat, Horse, Bedroom)[40].
        </p>
      </div>
      <img class="rounded" src="static/images/ASCED_results2.png" alt="Results" width="100%" height="auto">
    </div>
  </div>
</section>
<!-- End Experiment Results -->

<!-- Visualization -->
<!--   <section class="section" id="Visualization"> -->
<!--   <div class="container is-max-desktop content"> -->
<!--     <center> -->
<!--       <h2 class="title">Visualization</h2> -->
<!--     </center> -->
<!--     <div class="has-text-centered"> -->
<!--       <img class="rounded" src="static/images/ASCED_visual.png" alt="Visualization" width="70%" height="auto"> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> -->
<!-- End Visualization -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
          @inproceedings{cao2025temporal,
            title={Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts},
            author={Cao, Yu and Zhao, Zengqun and Patras, Ioannis and Gong, Shaogang},
            booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
            pages={7707--7716},
            year={2025}
          }
        </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
